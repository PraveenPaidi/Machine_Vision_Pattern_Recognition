{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c791870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "def harris_corner_detector(image, k=0.04, threshold=10000000000000):\n",
    "    \n",
    "        \n",
    "    ''' 1st step : providing image to calculate the gradients in x and y direction.\n",
    "    passing sobel kernel of size 5 to calculate and cv2.CV_64F is the output type'''\n",
    "    \n",
    "    I_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    I_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    ''' 2nd step , taking the mean out '''\n",
    "    mean_I_x = np.mean(I_x)\n",
    "    I_x -= mean_I_x\n",
    "    mean_I_y = np.mean(I_y)\n",
    "    I_y -= mean_I_y\n",
    "\n",
    "    ''' 3rd step , computing the covariance matrix '''\n",
    "    # computing the covariance matrix\n",
    "    I_x2 = I_x ** 2\n",
    "    I_y2 = I_y ** 2\n",
    "    I_xy = I_x * I_y\n",
    "\n",
    "    \n",
    "    ''' 4th step calculting eigen values and eigen vectors for M matrix '''\n",
    "    height, width= image.shape\n",
    "    window_size = 5\n",
    "\n",
    "    offset = window_size // 2\n",
    "\n",
    "    R = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    for y in range(offset, height - offset):\n",
    "        for x in range(offset, width - offset):\n",
    "            window_I_x2 = I_x2[y - offset:y + offset + 1, x - offset:x + offset + 1]\n",
    "            window_I_y2 = I_y2[y - offset:y + offset + 1, x - offset:x + offset + 1]\n",
    "            window_I_xy = I_xy[y - offset:y + offset + 1, x - offset:x + offset + 1]\n",
    "\n",
    "            M = np.array([[np.sum(window_I_x2), np.sum(window_I_xy)],\n",
    "                          [np.sum(window_I_xy), np.sum(window_I_y2)]], dtype=np.float32)\n",
    "            \n",
    "            eigvals = np.linalg.eigvals(M)\n",
    "\n",
    "            R[y, x] = min(eigvals) * max(eigvals) - k * ((min(eigvals) + max(eigvals))**2)\n",
    "\n",
    "    '''5th step corners finding my applying the thresshold as 1000 '''\n",
    "    corners = (R > threshold).nonzero()\n",
    "    return corners, R\n",
    "\n",
    "\n",
    "def ANMS(img, img_h, n_best, coords):\n",
    "    # list length of corners\n",
    "    ''' img being the original image, img_h being the liikelihood matrix of the harris corners'''\n",
    "    num = len(coords)\n",
    "    inf = sys.maxsize\n",
    "    r = inf * np.ones((num,3))\n",
    "    ED = 0\n",
    "    \n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            # taking one corner at a time.\n",
    "            x_i = coords[i][0]            \n",
    "            y_i = coords[i][1]            \n",
    "            \n",
    "            # comparing with all other corners.\n",
    "            neighbours_x = coords[j][0]  \n",
    "            neighbours_y = coords[j][1]\n",
    "            \n",
    "            \n",
    "            ''' taking the local maxima likelihood'''\n",
    "            if img_h[y_i,x_i] > img_h[neighbours_y,neighbours_x]:\n",
    "                ED = (neighbours_x - x_i)**2 + (neighbours_y - y_i)**2\n",
    "\n",
    "            if ED < r[i,0]:\n",
    "                r[i,0] = ED\n",
    "                r[i,1] = x_i\n",
    "                r[i,2] = y_i\n",
    "\n",
    "    arr = r[:,0]\n",
    "    #We get the index of biggest that is the reason of -ve sign(Descending order index)\n",
    "    feature_sorting = np.argsort(-arr)  \n",
    "    feature_cord = r[feature_sorting]\n",
    "    #We also can is find min of(n_best, num_of_feature_cordinates we got)\n",
    "    Nbest_corners = feature_cord[:n_best,:]   \n",
    "    \n",
    "    return Nbest_corners\n",
    "\n",
    "\n",
    "\n",
    "def feature_descriptors(img, corners,n_best,patch_size):\n",
    "    ''' sending the corner list and the image and the corner coordinates'''\n",
    "    n_descriptors = []\n",
    "    x = corners[:,1]\n",
    "    y = corners[:,2]\n",
    "\n",
    "    for i in range(n_best):\n",
    "        y_i = x[i]         \n",
    "        x_i = y[i]\n",
    "        gray = copy.deepcopy(img)\n",
    "        \n",
    "        #pad the image by 40 on all sides\n",
    "        gray = np.pad(img, ((patch_size,patch_size), (patch_size,patch_size)), mode='constant', constant_values=0)\n",
    "        x_start = int(x_i + patch_size/2)\n",
    "        y_start = int(y_i + patch_size/2)\n",
    "\n",
    "        # creating feature descriptor 40x40 descriptor of one point\n",
    "        descriptor = gray[x_start:x_start+patch_size, y_start:y_start+patch_size] \n",
    "        \n",
    "        # Applying gaussian blur on the descriptor\n",
    "        descriptor = cv2.GaussianBlur(descriptor, (7,7), cv2.BORDER_DEFAULT) \n",
    "               \n",
    "        # Sub sampling to 8x8   \n",
    "#         sub =5\n",
    "#         descriptor = descriptor[::sub,::sub]  \n",
    "               \n",
    "#         descriptor1 = descriptor.reshape((36,1))\n",
    "        descriptor1 = descriptor.reshape((patch_size*patch_size,1))\n",
    "                \n",
    "        std = descriptor1.std()\n",
    "        \n",
    "        if std< 0.00000001:\n",
    "            std = 0.000001\n",
    "\n",
    "        # to remove illumination invariance.\n",
    "        descriptor_standard = (descriptor1 - descriptor1.mean())/std\n",
    "            \n",
    "        n_descriptors.append(descriptor_standard)\n",
    "\n",
    "    return n_descriptors\n",
    "\n",
    "\n",
    "\n",
    "def feature_matching(Descriptors_image1, Descriptors_image2, corners1,corners2, match_ratio):\n",
    "    f1 = Descriptors_image1\n",
    "    f2 = Descriptors_image2\n",
    "    \n",
    "    matched_pairs = []\n",
    "    for i in range(0, len(f1)):\n",
    "        sqr_diff = []\n",
    "        for j in range(0, len(f2)):\n",
    "            # comparing each corner to every other corner in next image by taking the difference between the descriptors\n",
    "            diff = np.sum((f1[i] - f2[j])**2)\n",
    "            sqr_diff.append(diff)\n",
    "        # converting  into array  \n",
    "        sqr_diff = np.array(sqr_diff)\n",
    "        diff_sort = np.argsort(sqr_diff)\n",
    "        sqr_diff_sorted = sqr_diff[diff_sort]\n",
    "        \n",
    "        if (sqr_diff_sorted[1])==0:\n",
    "            sqr_diff_sorted[1] = 0.00001\n",
    "            \n",
    "        # applying lowe's algorithm to check the matching \n",
    "        ratio = sqr_diff_sorted[0]/(sqr_diff_sorted[1])\n",
    "        \n",
    "        if ratio < match_ratio :\n",
    "            matched_pairs.append((corners1[i,1:3], corners2[diff_sort[0],1:3]))\t\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "def dot_product(h_mat, keypoint):\n",
    "\tkeypoint = np.expand_dims(keypoint, 1)\n",
    "\tkeypoint = np.vstack([keypoint, 1])\n",
    "\tproduct = np.dot(h_mat, keypoint)\n",
    "\tif product[2]!=0:\n",
    "\t\tproduct = product/product[2]\n",
    "\telse:\n",
    "\t\tproduct = product/0.000001\n",
    "\t# print(product)\n",
    "\treturn product[0:2,:]\n",
    "\n",
    "def homography(point1, point2):\n",
    "    h_matrix  = cv2.getPerspectiveTransform(np.float32(point1), np.float32(point2))\n",
    "    return h_matrix\n",
    "\n",
    "def ransac(matched_pairs, threshold):\n",
    "\n",
    "    inliers = []   #to store ssd's and corresponding homography matrices\n",
    "    COUNT = []\n",
    "    for i in range(1000):    #Nmax iterations\n",
    "\n",
    "        keypoints_1 = [x[0] for x in matched_pairs]\n",
    "        keypoints_2 = [x[1] for x in matched_pairs]\n",
    "        length = len(keypoints_1)\n",
    "\n",
    "        randomlist = random.sample(range(0, length), 4)\n",
    "        points_1 = [keypoints_1[idx] for idx in randomlist]\n",
    "        points_2 = [keypoints_2[idx] for idx in randomlist]\n",
    "\n",
    "        h_matrix = homography(points_1, points_2)\n",
    "        # print(h_matrix)\n",
    "        points = []\n",
    "        count_inliers = 0\n",
    "        for i in range(length):\n",
    "            a = (np.array(keypoints_2[i]))\n",
    "            # ssd = np.sum((np.expand_dims(np.array(keypoints_2[i]), 1) - dot_product(h_matrix, keypoints_1[i]))**2)\n",
    "            ssd = np.linalg.norm(np.expand_dims(np.array(keypoints_2[i]), 1) - dot_product(h_matrix, keypoints_1[i]))\n",
    "            # print(\"ssd\",ssd)\n",
    "            if ssd < threshold:\n",
    "                count_inliers += 1\n",
    "                points.append((keypoints_1[i], keypoints_2[i]))\n",
    "        COUNT.append(-count_inliers)\n",
    "        inliers.append((h_matrix, points))\n",
    "    max_count_idx = np.argsort(COUNT)\n",
    "    max_count_idx = max_count_idx[0]\n",
    "    final_matched_pairs = inliers[max_count_idx][1]\n",
    "    # print(\"Matched pairs\", len(final_matched_pairs))\n",
    "\n",
    "    pts_1 = [x[0] for x in final_matched_pairs]\n",
    "    pts_2 = [x[1] for x in final_matched_pairs]\n",
    "    h_final_matrix, status = cv2.findHomography(np.float32(pts_1),np.float32(pts_2))\n",
    "    # print(h_final_matrix)\n",
    "    return h_final_matrix, final_matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "aa87b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "\n",
    "image1=cv2.imread(r'..\\final\\random_quadrilateral_centered1.png',cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread(r'..\\final\\Rotated1.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "0f11e459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect corners using harris corners \n",
    "corners1,R1 = harris_corner_detector(img1)\n",
    "corners2,R2 = harris_corner_detector(img2)\n",
    "\n",
    "corner_list1=[]\n",
    "corner_list2=[]\n",
    "\n",
    "# Draw corners on the image\n",
    "for x, y in zip(corners1[1], corners1[0]):\n",
    "    cv2.circle(img1, (x, y), 2, 100, -1)\n",
    "    corner_list1.append((x,y))\n",
    "    \n",
    "for x, y in zip(corners2[1], corners2[0]):\n",
    "    cv2.circle(img2, (x, y), 2, 100, -1)\n",
    "    corner_list2.append((x,y))\n",
    "    \n",
    "# Display or save the result\n",
    "cv2.imwrite('Harris Corners Orig.jpg', img1)\n",
    "cv2.imwrite('Harris Corners Roatated.jpg', img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "945e7a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1=cv2.imread(r'..\\final\\random_quadrilateral_centered1.png')\n",
    "image2 = cv2.imread(r'..\\final\\Rotated1.png')\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "\n",
    "# Adaptive Non Max Supression\n",
    "n_best =70\n",
    "Best_corners1 = ANMS(img1, R1, n_best, corner_list1 )\n",
    "\n",
    "for i in range(len(Best_corners1)):\n",
    "    cv2.circle(img1, (int(Best_corners1[i][1]),int(Best_corners1[i][2])), 3, 100, -1)\n",
    "cv2.imwrite('Anms1.jpg', img1)\n",
    "\n",
    "Best_corners2 = ANMS(img2, R2, n_best, corner_list2 )\n",
    "\n",
    "for i in range(len(Best_corners2)):\n",
    "    cv2.circle(img2, (int(Best_corners2[i][1]),int(Best_corners2[i][2])), 3, 100, -1)\n",
    "cv2.imwrite(\"anms2.png\",img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "9790cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=cv2.imread(r'..\\final\\random_quadrilateral_centered1.png',cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread(r'..\\final\\Rotated1.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "\n",
    "# applying SIFT to get the feature descriptors \n",
    "patch_size= 22\n",
    "Descriptors_image1= feature_descriptors(img1, Best_corners1, n_best, patch_size)\n",
    "Descriptors_image2= feature_descriptors(img2, Best_corners2, n_best, patch_size)\n",
    "\n",
    "matched_pairs= feature_matching(Descriptors_image1, Descriptors_image2, Best_corners1,Best_corners2, match_ratio=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6a4bb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "file_path = 'final_matches_before_ransac.txt'\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(file_path, 'w') as file:\n",
    "    # Write each match to a new line in the file\n",
    "    for match in matched_pairs:\n",
    "        file.write(str(match) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3141ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "final_h_mat, final_matched = ransac(matched_pairs, threshold=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f81cd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matched = [(a.astype(int), b.astype(int)) for a, b in final_matched]\n",
    "final_matched\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "def keypoint(points):\n",
    "\tkp1 = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tkp1.append(cv2.KeyPoint(int(points[i][0]), int(points[i][1]), 3))\n",
    "\treturn kp1\n",
    "\n",
    "def matches(points):\n",
    "\tm = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tm.append(cv2.DMatch(int(points[i][0]), int(points[i][1]), 2))\n",
    "\treturn m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "9dc07f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(img1,img2, matched_pairs):\n",
    "\tkey_points_1 = [x[0] for x in matched_pairs]\n",
    "\tkeypoints1 = keypoint(key_points_1)\n",
    "\tkey_points_2 = [x[1] for x in matched_pairs]\n",
    "\tkeypoints2 = keypoint(key_points_2)\n",
    "\tmatched_pairs_idx = [(i,i) for i,j in enumerate(matched_pairs)]\n",
    "\tmatches1to2 = matches(matched_pairs_idx)\n",
    "\tout = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, None, flags =2)\n",
    "\tcv2.imwrite('out.jpg',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ef49d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_matches(img1,img2, final_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "683637fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'final_matches.txt'\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(file_path, 'w') as file:\n",
    "    # Write each match to a new line in the file\n",
    "    for match in final_matched:\n",
    "        file.write(str(match) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6e75ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matched = [(a.astype(int), b.astype(int)) for a, b in matched_pairs]\n",
    "final_matched\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "def keypoint(points):\n",
    "\tkp1 = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tkp1.append(cv2.KeyPoint(int(points[i][0]), int(points[i][1]), 3))\n",
    "\treturn kp1\n",
    "\n",
    "def matches(points):\n",
    "\tm = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tm.append(cv2.DMatch(int(points[i][0]), int(points[i][1]), 2))\n",
    "\treturn m\n",
    "\n",
    "def draw_matches(img1,img2, matched_pairs):\n",
    "\tkey_points_1 = [x[0] for x in matched_pairs]\n",
    "\tkeypoints1 = keypoint(key_points_1)\n",
    "\tkey_points_2 = [x[1] for x in matched_pairs]\n",
    "\tkeypoints2 = keypoint(key_points_2)\n",
    "\tmatched_pairs_idx = [(i,i) for i,j in enumerate(matched_pairs)]\n",
    "\tmatches1to2 = matches(matched_pairs_idx)\n",
    "\tout = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, None, flags =2)\n",
    "\tcv2.imwrite('without_ransac.jpg',out)\n",
    "    \n",
    "draw_matches(img1,img2, final_matched)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203cd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
