{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5cf292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "def harris_corner_detector(image, k=0.04, threshold=1500000000000000):   #10000000000000000\n",
    "    \n",
    "        \n",
    "    ''' 1st step : providing image to calculate the gradients in x and y direction.\n",
    "    passing sobel kernel of size 5 to calculate and cv2.CV_64F is the output type'''\n",
    "    \n",
    "    I_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    I_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    ''' 2nd step , taking the mean out '''\n",
    "    mean_I_x = np.mean(I_x)\n",
    "    I_x -= mean_I_x\n",
    "    mean_I_y = np.mean(I_y)\n",
    "    I_y -= mean_I_y\n",
    "\n",
    "    ''' 3rd step , computing the covariance matrix '''\n",
    "    # computing the covariance matrix\n",
    "    I_x2 = I_x ** 2\n",
    "    I_y2 = I_y ** 2\n",
    "    I_xy = I_x * I_y\n",
    "\n",
    "    \n",
    "    ''' 4th step calculting eigen values and eigen vectors for M matrix '''\n",
    "    height, width= image.shape\n",
    "    window_size = 5\n",
    "\n",
    "    offset = window_size // 2\n",
    "\n",
    "    R = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    for y in range(offset, height - offset):\n",
    "        for x in range(offset, width - offset):\n",
    "            window_I_x2 = I_x2[y - offset:y + offset + 1, x - offset:x + offset + 1]\n",
    "            window_I_y2 = I_y2[y - offset:y + offset + 1, x - offset:x + offset + 1]\n",
    "            window_I_xy = I_xy[y - offset:y + offset + 1, x - offset:x + offset + 1]\n",
    "\n",
    "            M = np.array([[np.sum(window_I_x2), np.sum(window_I_xy)],\n",
    "                          [np.sum(window_I_xy), np.sum(window_I_y2)]], dtype=np.float32)\n",
    "            \n",
    "            eigvals = np.linalg.eigvals(M)\n",
    "\n",
    "            R[y, x] = min(eigvals) * max(eigvals) - k * ((min(eigvals) + max(eigvals))**2)\n",
    "\n",
    "    '''5th step corners finding my applying the thresshold as 1000 '''\n",
    "    corners = (R > threshold).nonzero()\n",
    "    return corners, R\n",
    "\n",
    "\n",
    "def ANMS(img, img_h, n_best, coords):\n",
    "    # list length of corners\n",
    "    ''' img being the original image, img_h being the liikelihood matrix of the harris corners'''\n",
    "    num = len(coords)\n",
    "    inf = sys.maxsize\n",
    "    r = inf * np.ones((num,3))\n",
    "    ED = 0\n",
    "    \n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            # taking one corner at a time.\n",
    "            x_i = coords[i][0]            \n",
    "            y_i = coords[i][1]            \n",
    "            \n",
    "            # comparing with all other corners.\n",
    "            neighbours_x = coords[j][0]  \n",
    "            neighbours_y = coords[j][1]\n",
    "            \n",
    "            \n",
    "            ''' taking the local maxima likelihood'''\n",
    "            if img_h[y_i,x_i] > img_h[neighbours_y,neighbours_x]:\n",
    "                ED = (neighbours_x - x_i)**2 + (neighbours_y - y_i)**2\n",
    "\n",
    "            if ED < r[i,0]:\n",
    "                r[i,0] = ED\n",
    "                r[i,1] = x_i\n",
    "                r[i,2] = y_i\n",
    "\n",
    "    arr = r[:,0]\n",
    "    #We get the index of biggest that is the reason of -ve sign(Descending order index)\n",
    "    feature_sorting = np.argsort(-arr)  \n",
    "    feature_cord = r[feature_sorting]\n",
    "    #We also can is find min of(n_best, num_of_feature_cordinates we got)\n",
    "    Nbest_corners = feature_cord[:n_best,:]   \n",
    "    \n",
    "    return Nbest_corners\n",
    "\n",
    "\n",
    "\n",
    "def feature_descriptors(img, corners,n_best,patch_size):\n",
    "    ''' sending the corner list and the image and the corner coordinates'''\n",
    "    n_descriptors = []\n",
    "    x = corners[:,1]\n",
    "    y = corners[:,2]\n",
    "\n",
    "    for i in range(n_best):\n",
    "        y_i = x[i]         \n",
    "        x_i = y[i]\n",
    "        gray = copy.deepcopy(img)\n",
    "        \n",
    "        #pad the image by 40 on all sides\n",
    "        gray = np.pad(img, ((patch_size,patch_size), (patch_size,patch_size)), mode='constant', constant_values=0)\n",
    "        x_start = int(x_i + patch_size/2)\n",
    "        y_start = int(y_i + patch_size/2)\n",
    "\n",
    "        # creating feature descriptor 40x40 descriptor of one point\n",
    "        descriptor = gray[x_start:x_start+patch_size, y_start:y_start+patch_size] \n",
    "        \n",
    "        # Applying gaussian blur on the descriptor\n",
    "        descriptor = cv2.GaussianBlur(descriptor, (7,7), cv2.BORDER_DEFAULT) \n",
    "               \n",
    "        # Sub sampling to 8x8   \n",
    "        sub =5\n",
    "        descriptor = descriptor[::sub,::sub]  \n",
    "               \n",
    "        descriptor1 = descriptor.reshape((64,1))\n",
    "                \n",
    "        std = descriptor1.std()\n",
    "        \n",
    "        if std< 0.00000001:\n",
    "            std = 0.000001\n",
    "\n",
    "        # to remove illumination invariance.\n",
    "        descriptor_standard = (descriptor1 - descriptor1.mean())/std\n",
    "            \n",
    "        n_descriptors.append(descriptor_standard)\n",
    "\n",
    "    return n_descriptors\n",
    "\n",
    "\n",
    "\n",
    "def feature_matching(Descriptors_image1, Descriptors_image2, corners1,corners2, match_ratio):\n",
    "    f1 = Descriptors_image1\n",
    "    f2 = Descriptors_image2\n",
    "    \n",
    "    matched_pairs = []\n",
    "    for i in range(0, len(f1)):\n",
    "        sqr_diff = []\n",
    "        for j in range(0, len(f2)):\n",
    "            # comparing each corner to every other corner in next image by taking the difference between the descriptors\n",
    "            diff = np.sum((f1[i] - f2[j])**2)\n",
    "            sqr_diff.append(diff)\n",
    "        # converting  into array  \n",
    "        sqr_diff = np.array(sqr_diff)\n",
    "        diff_sort = np.argsort(sqr_diff)\n",
    "        sqr_diff_sorted = sqr_diff[diff_sort]\n",
    "        \n",
    "        if (sqr_diff_sorted[1])==0:\n",
    "            sqr_diff_sorted[1] = 0.00001\n",
    "            \n",
    "        # applying lowe's algorithm to check the matching \n",
    "        ratio = sqr_diff_sorted[0]/(sqr_diff_sorted[1])\n",
    "        \n",
    "        if ratio < match_ratio :\n",
    "            matched_pairs.append((corners1[i,1:3], corners2[diff_sort[0],1:3]))\t\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "def dot_product(h_mat, keypoint):\n",
    "\tkeypoint = np.expand_dims(keypoint, 1)\n",
    "\tkeypoint = np.vstack([keypoint, 1])\n",
    "\tproduct = np.dot(h_mat, keypoint)\n",
    "\tif product[2]!=0:\n",
    "\t\tproduct = product/product[2]\n",
    "\telse:\n",
    "\t\tproduct = product/0.000001\n",
    "\t# print(product)\n",
    "\treturn product[0:2,:]\n",
    "\n",
    "def homography(point1, point2):\n",
    "    h_matrix  = cv2.getPerspectiveTransform(np.float32(point1), np.float32(point2))\n",
    "    return h_matrix\n",
    "\n",
    "def ransac(matched_pairs, threshold):\n",
    "\n",
    "    inliers = []   #to store ssd's and corresponding homography matrices\n",
    "    COUNT = []\n",
    "    for i in range(1000):    #Nmax iterations\n",
    "\n",
    "        keypoints_1 = [x[0] for x in matched_pairs]\n",
    "        keypoints_2 = [x[1] for x in matched_pairs]\n",
    "        length = len(keypoints_1)\n",
    "\n",
    "        randomlist = random.sample(range(0, length), 4)\n",
    "        points_1 = [keypoints_1[idx] for idx in randomlist]\n",
    "        points_2 = [keypoints_2[idx] for idx in randomlist]\n",
    "\n",
    "        h_matrix = homography(points_1, points_2)\n",
    "        # print(h_matrix)\n",
    "        points = []\n",
    "        count_inliers = 0\n",
    "        for i in range(length):\n",
    "            a = (np.array(keypoints_2[i]))\n",
    "            # ssd = np.sum((np.expand_dims(np.array(keypoints_2[i]), 1) - dot_product(h_matrix, keypoints_1[i]))**2)\n",
    "            ssd = np.linalg.norm(np.expand_dims(np.array(keypoints_2[i]), 1) - dot_product(h_matrix, keypoints_1[i]))\n",
    "            # print(\"ssd\",ssd)\n",
    "            if ssd < threshold:\n",
    "                count_inliers += 1\n",
    "                points.append((keypoints_1[i], keypoints_2[i]))\n",
    "        COUNT.append(-count_inliers)\n",
    "        inliers.append((h_matrix, points))\n",
    "    max_count_idx = np.argsort(COUNT)\n",
    "    max_count_idx = max_count_idx[0]\n",
    "    final_matched_pairs = inliers[max_count_idx][1]\n",
    "    # print(\"Matched pairs\", len(final_matched_pairs))\n",
    "\n",
    "    pts_1 = [x[0] for x in final_matched_pairs]\n",
    "    pts_2 = [x[1] for x in final_matched_pairs]\n",
    "    h_final_matrix, status = cv2.findHomography(np.float32(pts_1),np.float32(pts_2))\n",
    "    # print(h_final_matrix)\n",
    "    return h_final_matrix, final_matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4275a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "\n",
    "image1=cv2.imread(r'..\\Prob 5\\1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread(r'..\\Prob 5\\2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb189064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect corners using harris corners \n",
    "corners1,R1 = harris_corner_detector(img1)\n",
    "corners2,R2 = harris_corner_detector(img2)\n",
    "\n",
    "corner_list1=[]\n",
    "corner_list2=[]\n",
    "\n",
    "    \n",
    "image1=cv2.imread(r'..\\Prob 5\\1.jpg')\n",
    "image2 = cv2.imread(r'..\\Prob 5\\2.jpg')\n",
    "\n",
    "# Display or save the result\n",
    "cv2.imwrite('Harris Corners Orig.jpg', image1)\n",
    "cv2.imwrite('Harris Corners Roatated.jpg', image2)\n",
    "\n",
    "# Draw corners on the image\n",
    "for x, y in zip(corners1[1], corners1[0]):\n",
    "    cv2.circle(img1, (x, y), 2, 100, -1)\n",
    "    corner_list1.append((x,y))\n",
    "    \n",
    "for x, y in zip(corners2[1], corners2[0]):\n",
    "    cv2.circle(img2, (x, y), 2, 100, -1)\n",
    "    corner_list2.append((x,y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2635731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74627"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corner_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c6b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd15914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31d479a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1=cv2.imread(r'..\\Prob 5\\1.jpg')\n",
    "image2 = cv2.imread(r'..\\Prob 5\\2.jpg')\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "\n",
    "# Adaptive Non Max Supression\n",
    "n_best =1000\n",
    "Best_corners1 = ANMS(img1, R1, n_best, corner_list1 )\n",
    "\n",
    "for i in range(len(Best_corners1)):\n",
    "    cv2.circle(img1, (int(Best_corners1[i][1]),int(Best_corners1[i][2])), 3, 100, -1)\n",
    "cv2.imwrite('Anms1.jpg', img1)\n",
    "\n",
    "Best_corners2 = ANMS(img2, R2, n_best, corner_list2 )\n",
    "\n",
    "for i in range(len(Best_corners2)):\n",
    "    cv2.circle(img2, (int(Best_corners2[i][1]),int(Best_corners2[i][2])), 3, 100, -1)\n",
    "cv2.imwrite(\"anms2.png\",img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69ba12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "68068a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=cv2.imread(r'..\\Prob 5\\1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread(r'..\\Prob 5\\2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "\n",
    "# applying SIFT to get the feature descriptors \n",
    "patch_size= 40\n",
    "Descriptors_image1= feature_descriptors(img1, Best_corners1, n_best, patch_size)\n",
    "Descriptors_image2= feature_descriptors(img2, Best_corners2, n_best, patch_size)\n",
    "\n",
    "matched_pairs= feature_matching(Descriptors_image1, Descriptors_image2, Best_corners1,Best_corners2, match_ratio=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10f1a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([581., 784.]), array([ 84., 769.])),\n",
       " (array([778., 913.]), array([276., 895.])),\n",
       " (array([708., 595.]), array([239., 578.])),\n",
       " (array([792., 738.]), array([313., 723.])),\n",
       " (array([  5., 473.]), array([  6., 518.])),\n",
       " (array([177., 501.]), array([214., 572.])),\n",
       " (array([768., 795.]), array([271., 779.])),\n",
       " (array([747., 555.]), array([277., 539.])),\n",
       " (array([989., 890.]), array([234., 963.])),\n",
       " (array([509., 531.]), array([181., 544.])),\n",
       " (array([626., 932.]), array([119., 926.])),\n",
       " (array([754., 966.]), array([241., 952.])),\n",
       " (array([546., 540.]), array([216., 610.])),\n",
       " (array([690., 628.]), array([216., 610.])),\n",
       " (array([301., 605.]), array([180., 629.])),\n",
       " (array([687., 565.]), array([214., 543.])),\n",
       " (array([295., 878.]), array([549., 647.])),\n",
       " (array([974., 578.]), array([479., 579.])),\n",
       " (array([764., 696.]), array([  11., 1132.])),\n",
       " (array([635., 888.]), array([129., 848.])),\n",
       " (array([787., 620.]), array([307., 608.])),\n",
       " (array([837., 588.]), array([362., 579.])),\n",
       " (array([804., 581.]), array([330., 568.])),\n",
       " (array([720., 540.]), array([250., 521.])),\n",
       " (array([466., 579.]), array([216., 599.])),\n",
       " (array([659., 570.]), array([181., 544.])),\n",
       " (array([178., 473.]), array([216., 610.])),\n",
       " (array([338., 489.]), array([214., 543.])),\n",
       " (array([950., 766.]), array([448., 750.])),\n",
       " (array([401., 867.]), array([474., 755.])),\n",
       " (array([815., 688.]), array([332., 674.])),\n",
       " (array([747., 530.]), array([279., 515.])),\n",
       " (array([914., 708.]), array([420., 695.])),\n",
       " (array([ 948., 1146.]), array([ 387., 1101.])),\n",
       " (array([ 702., 1269.]), array([ 131., 1266.])),\n",
       " (array([569., 801.]), array([ 71., 791.])),\n",
       " (array([645., 920.]), array([276., 895.])),\n",
       " (array([709., 625.]), array([238., 607.])),\n",
       " (array([826., 753.]), array([337., 739.])),\n",
       " (array([ 702., 1163.]), array([ 149., 1160.])),\n",
       " (array([ 672., 1158.]), array([ 118., 1159.])),\n",
       " (array([757., 781.]), array([261., 765.])),\n",
       " (array([910., 758.]), array([412., 740.])),\n",
       " (array([711., 655.]), array([235., 635.])),\n",
       " (array([  4., 851.]), array([   3., 1195.])),\n",
       " (array([787., 647.]), array([307., 629.])),\n",
       " (array([846., 740.]), array([358., 726.])),\n",
       " (array([585., 769.]), array([ 86., 755.])),\n",
       " (array([636., 852.]), array([129., 848.])),\n",
       " (array([896., 820.]), array([400., 798.])),\n",
       " (array([ 805., 1341.]), array([ 141., 1341.])),\n",
       " (array([750., 794.]), array([255., 782.])),\n",
       " (array([405., 727.]), array([549., 647.])),\n",
       " (array([543., 526.]), array([ 51., 487.])),\n",
       " (array([ 843., 1169.]), array([ 292., 1138.])),\n",
       " (array([635., 865.]), array([129., 848.])),\n",
       " (array([859., 779.]), array([368., 761.])),\n",
       " (array([585., 929.]), array([ 76., 927.])),\n",
       " (array([ 958., 1156.]), array([ 394., 1110.])),\n",
       " (array([ 540., 1189.]), array([803., 745.])),\n",
       " (array([872., 730.]), array([385., 715.])),\n",
       " (array([627., 780.]), array([125., 767.])),\n",
       " (array([ 248., 1120.]), array([ 975., 1078.])),\n",
       " (array([879., 837.]), array([386., 815.])),\n",
       " (array([808., 657.]), array([327., 641.])),\n",
       " (array([757., 639.]), array([280., 624.])),\n",
       " (array([  2., 944.]), array([   2., 1158.])),\n",
       " (array([822., 701.]), array([339., 687.])),\n",
       " (array([690., 618.]), array([216., 599.]))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "42d421fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "final_h_mat, final_matched = ransac(matched_pairs, threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "093682b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matched = [(a.astype(int), b.astype(int)) for a, b in final_matched]\n",
    "final_matched\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "def keypoint(points):\n",
    "\tkp1 = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tkp1.append(cv2.KeyPoint(int(points[i][0]), int(points[i][1]), 3))\n",
    "\treturn kp1\n",
    "\n",
    "def matches(points):\n",
    "\tm = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tm.append(cv2.DMatch(int(points[i][0]), int(points[i][1]), 2))\n",
    "\treturn m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a674378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(img1,img2, matched_pairs):\n",
    "\tkey_points_1 = [x[0] for x in matched_pairs]\n",
    "\tkeypoints1 = keypoint(key_points_1)\n",
    "\tkey_points_2 = [x[1] for x in matched_pairs]\n",
    "\tkeypoints2 = keypoint(key_points_2)\n",
    "\tmatched_pairs_idx = [(i,i) for i,j in enumerate(matched_pairs)]\n",
    "\tmatches1to2 = matches(matched_pairs_idx)\n",
    "\tout = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, None, flags =2)\n",
    "\tcv2.imwrite('out.jpg',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "285e30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_matches(img1,img2, final_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eba9c7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_pairs_idx = [(i,i) for i,j in enumerate(final_matched)]\n",
    "matches1to2 = matches(matched_pairs_idx)\n",
    "keypoints1 = [x[0] for x in final_matched]\n",
    "keypoints2 = [x[1] for x in final_matched]\n",
    "\n",
    "def keypoint(points):\n",
    "\tkp1 = []\n",
    "\tfor i in range(len(points)):\n",
    "\t\tkp1.append(cv2.KeyPoint(int(points[i][0]), int(points[i][1]), 3))\n",
    "\treturn kp1\n",
    "\n",
    "keypoints1= keypoint(keypoints1)\n",
    "keypoints2= keypoint(keypoints2)\n",
    "\n",
    "out = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches1to2, None, flags =2)\n",
    "cv2.imwrite('outliers.jpg',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5f210f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2, H):\n",
    "\n",
    "\timg1 = img1\n",
    "\timg2 = img2\n",
    "\th1,w1 = img1.shape[:2]\n",
    "\th2,w2 = img2.shape[:2]\n",
    "\tpts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "\tpts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "\tpts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "\tpts = np.concatenate((pts1, pts2_), axis=0)\n",
    "\t[xmin, ymin] = np.int32(pts.min(axis=0).ravel())\n",
    "\t[xmax, ymax] = np.int32(pts.max(axis=0).ravel())\n",
    "\tt = [-xmin,-ymin]\n",
    "\tHt = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "\tresult = cv2.warpPerspective(img1, Ht.dot(H), (xmax-xmin, ymax-ymin), flags = cv2.INTER_LINEAR)\n",
    "\tresult[t[1]:h1+t[1],t[0]:w1+t[0]] = img2\n",
    "\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2f531d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=cv2.imread(r'..\\Prob 5\\1.jpg')\n",
    "image2 = cv2.imread(r'..\\Prob 5\\2.jpg')\n",
    "\n",
    "img1 = copy.deepcopy(image1)\n",
    "img2 = copy.deepcopy(image2)\n",
    "\n",
    "warped = warpTwoImages(img1, img2, final_h_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0e2a61ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('warp.jpg',warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5861863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b21be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98614374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ac6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389cc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887a034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb36d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07882b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1=cv2.imread(r'..\\Prob 5\\1.jpg')\n",
    "image2 = cv2.imread(r'..\\Prob 5\\2.jpg')\n",
    "\n",
    "re1= cv2.resize(image1, (506*2,672*2 ))\n",
    "\n",
    "re2= cv2.resize(image2, (506*2,672*2 ))\n",
    "\n",
    "cv2.imwrite('1.jpg', re1)\n",
    "cv2.imwrite('2.jpg', re2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bb1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
